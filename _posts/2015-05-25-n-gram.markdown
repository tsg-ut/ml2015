---
layout: post
title:  "#07 N-gramによるテキスト分類"
date:   2015-05-25
categories: ml
---

## N-gramモデル

上記の例では単語分割（形態素解析というやつ）ができている前提で話を進めていたが，実際に形態素解析を行うのは（というか環境構築するのが）それなりに面倒なことが多い．
形態素解析を行いたいのであれば，日本語なら[MeCab](http://taku910.github.io/mecab/)を使うのが現状最もよい選択肢であると言える．
Python向けバインディングもあるので比較的扱いやすい．
（余談だが，日本語の係り受け解析であれば同じく京大の開発した[Cabocha](http://taku910.github.io/cabocha/)が良い．使ってみるととても楽しい．これらの自然言語解析モジュール自体も機械学習を用いている）

ここでは，自然言語処理を行う上で便利なモデルとして，**N-gram**を紹介する．

N-gramとは，「文章のi文字目(iは1〜(文章長-N)まで)から連続するN文字を取り出し，その文章の特徴とする」モデルである．

![N-gram]({{ site.baseurl }}/images/07/n-gram.001.jpg)

【Reference】[N-gramモデルを利用したテキスト分析](http://www.shuiren.org/chuden/teach/n-gram/index-j.html)

これだけだと本当に文章の特徴を捉えているのか心配になりそうだが，N-gramだけでもそれなりにテキストの素性を捉えることができることが知られている．
一つには，文章中の（あまり離れていない）共起関係（ググってください…）を比較的容易に捉えられる点があげられる．
勿論，これだけシンプル故に欠点もたくさんある．
